<h2 align="center">[IJCAI 2024] EvDiff: Event-driven Motion-aware Diffusion for Joint Low-Light Enhancement and Deblurring</h2>

<hr />

> **Abstract:** *Night photography often grapples with low light and motion blur due to the dark environments and dynamic scenes. To achieve the goal of improving visibility and deblurring while preserving intrinsical details during an end-to-end process, this paper proposes an \textbf{Ev}ent-driven \textbf{Diff}usion-based method (EvDiff) to address the joint degradation. Specifically, inspired by color constancy literature, we first formulate an adaptive histogram-based regularization term based on the reverse process of diffusion to balance the light enhancement and deblurring, which can gradually facilitate the preservation of complicated details and the augmentation of contrast. This incorporation mitigates the adverse effects of removing informative clues for blur removal, leading to a more harmonious and realistic result. Additionally, we devise a pyramid-motion-aware module that extracts motion cues from the corresponding event sequence. These cues serve as ancillary guidance, seamlessly incorporated into the learning process, thereby fortifying the robustness of our methodology. This strategic design effectively circumvents overfitting to specific data distributions and reduces the generation of artifacts. Experimental evaluations reveal that the proposed event-driven diffusion-based framework attains superior performance in addressing low light and motion blur joint degradation and has robustness when facing out-of-domain data distribution.* 
<hr />

## Network Architecture


## Training

[//]: # (Run `python setup.py develop --no_cuda_ext` to install basicsr.)
```
 Coming soon.

```


## Evaluation
```
 Coming soon.

```


 
